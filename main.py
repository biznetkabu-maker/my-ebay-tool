import asyncio
import os
import json
import re
import gspread
import httpx
from google.oauth2.service_account import Credentials
from playwright.async_api import async_playwright

# --- è¨­å®š ---
SHEET_NAME = "Indevia.system"
WORKSHEET_NAME = "02_Purchase_Control"
LINE_TOKEN = os.getenv("LINE_NOTIFY_TOKEN")  # ä»»æ„

def line_notify(msg):
    if not LINE_TOKEN:
        return
    url = "https://notify-api.line.me/api/notify"
    headers = {"Authorization": f"Bearer {LINE_TOKEN}"}
    data = {"message": msg}
    try:
        httpx.post(url, headers=headers, data=data, timeout=10)
    except:
        pass

def get_gspread_client():
    scope = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive'
    ]
    env_json = os.getenv("GSPREAD_SERVICE_ACCOUNT")
    if not env_json:
        raise ValueError("âŒ Secrets 'GSPREAD_SERVICE_ACCOUNT' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    key_json = json.loads(env_json)
    creds = Credentials.from_service_account_info(key_json, scopes=scope)
    return gspread.authorize(creds)

async def update_spreadsheet(data_list):
    if not data_list:
        print("âš ï¸ æ›¸ãè¾¼ã‚€ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return
    try:
        client = get_gspread_client()
        sheet = client.open(SHEET_NAME).worksheet(WORKSHEET_NAME)
        rows = [[
            item['jan'],
            item['price'],
            item['shop'],
            item['url'],
            item.get('image', ''),
            item.get('category', ''),
            '', '', '', '',
            item['name']
        ] for item in data_list]
        sheet.append_rows(rows)
        print(f"âœ… ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã« {len(rows)} ä»¶æ›¸ãè¾¼ã¿ã¾ã—ãŸï¼")
    except Exception as e:
        print(f"âŒ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# --- Yahooä¾¡æ ¼è£œå®Œï¼ˆPlaywrightï¼‰ ---
async def scrape_yahoo_price(page, url):
    try:
        await page.goto(url, wait_until="load", timeout=60000)
        price_el = await page.query_selector('span[class*="Price__value"]')
        if price_el:
            price_text = await price_el.inner_text()
            price_match = re.search(r"[0-9,]+", price_text)
            if price_match:
                return int(price_match.group(0).replace(",", ""))
    except Exception as e:
        print(f"âŒ Yahooä¾¡æ ¼è£œå®Œã‚¨ãƒ©ãƒ¼: {e}")
    return None

# --- æ¥½å¤© ---
async def fetch_rakuten(keyword):
    app_id = os.getenv("RAKUTEN_APP_ID")
    if not app_id:
        return []
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20220601"
    params = {
        "applicationId": app_id,
        "keyword": keyword,
        "hits": 3,
        "format": "json",
        "sort": "+itemPrice"
    }
    async with httpx.AsyncClient() as client:
        try:
            res = await client.get(url, params=params)
            if res.status_code != 200:
                return []
            items = res.json().get("Items", [])
            return [{
                "jan": i["Item"].get("janCode") or keyword,
                "name": i["Item"]["itemName"],
                "price": i["Item"]["itemPrice"],
                "shop": "æ¥½å¤©",
                "url": i["Item"]["itemUrl"],
                "image": i["Item"].get("mediumImageUrls", [{}])[0].get("imageUrl", ""),
                "category": i["Item"].get("genreId", "")
            } for i in items]
        except Exception:
            return []

# --- Yahooï¼ˆä¾¡æ ¼è£œå®Œä»˜ãï¼‰ ---
async def fetch_yahoo(keyword, page):
    client_id = os.getenv("YAHOO_CLIENT_ID")
    if not client_id:
        return []
    url = "https://shopping.yahooapis.jp/ShoppingWebService/V3/itemSearch"
    params = {
        "appid": client_id,
        "query": keyword,
        "results": 3,
        "sort": "+price"
    }
    async with httpx.AsyncClient() as client:
        try:
            res = await client.get(url, params=params)
            if res.status_code != 200:
                print(f"âš ï¸ YahooAPIã‚¨ãƒ©ãƒ¼: Status {res.status_code}")
                return []
            hits = res.json().get("hits", [])
            results = []
            for h in hits:
                price = h.get("price")
                url = h.get("url")

                # price==1 â†’ è£œå®Œ
                if price == 1 and url:
                    price = await scrape_yahoo_price(page, url)

                results.append({
                    "jan": h.get("jan_code") or keyword,
                    "name": h.get("name"),
                    "price": price,
                    "shop": "Yahoo",
                    "url": url,
                    "image": h.get("image", {}).get("medium", ""),
                    "category": h.get("category_id", "")
                })
            return results
        except Exception:
            return []

# --- ã˜ã‚ƒã‚“ã±ã‚‰ ---
async def fetch_janpara(page, keyword):
    results = []
    try:
        url = f"https://www.janpara.co.jp/sale/search/detail/?KEYWORDS={keyword}"
        await page.goto(url, wait_until="load", timeout=60000)
        items = await page.query_selector_all("a")
        for item in items:
            text = await item.inner_text()
            href = await item.get_attribute("href")
            if text and "å††" in text and href and "ITMCODE" in href:
                price_match = re.search(r"([0-9,]+)å††", text.replace("\n", ""))
                if price_match:
                    price = int(price_match.group(1).replace(",", ""))
                    lines = [l.strip() for l in text.split("\n") if l.strip()]
                    name = max(lines, key=len) if lines else keyword
                    results.append({
                        "jan": keyword,
                        "name": name,
                        "price": price,
                        "shop": "ã˜ã‚ƒã‚“ã±ã‚‰",
                        "url": f"https://www.janpara.co.jp{href}",
                        "image": "",
                        "category": ""
                    })
            if len(results) >= 3:
                break
    except Exception as e:
        print(f"âŒ ã˜ã‚ƒã‚“ã±ã‚‰å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    return results

# --- ãƒ¡ã‚¤ãƒ³ ---
async def main():
    try:
        client = get_gspread_client()
        sheet = client.open(SHEET_NAME).worksheet(WORKSHEET_NAME)
        keywords = [v for v in sheet.col_values(1)[1:] if v]
        if not keywords:
            print("âŒ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context()
            page = await context.new_page()
            for keyword in keywords:
                print(f"ğŸ” '{keyword}' ã‚’æ¤œç´¢ä¸­...")
                all_data = []
                all_data.extend(await fetch_rakuten(keyword))
                all_data.extend(await fetch_yahoo(keyword, page))
                all_data.extend(await fetch_janpara(page, keyword))
                print(f"ğŸ“Š {keyword}: {len(all_data)} ä»¶å–å¾—")
                await update_spreadsheet(all_data)
            await browser.close()
        line_notify("âœ… Invedia Scraper å®Œäº†ã—ã¾ã—ãŸ")
        print("--- å…¨å·¥ç¨‹çµ‚äº† ---")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        line_notify(f"âŒ Scraper ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    asyncio.run(main())
